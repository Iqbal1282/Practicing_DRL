{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d4d38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  2 20:52:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   42C    P8             11W /  285W |    1297MiB /  12282MiB |     17%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        24      G   /Xwayland                                   N/A      |\n",
      "|    0   N/A  N/A        36      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d361de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings ; warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import threading\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from itertools import cycle, count\n",
    "from textwrap import wrap\n",
    "\n",
    "import pybullet_envs\n",
    "import matplotlib\n",
    "import subprocess\n",
    "import os.path\n",
    "import tempfile\n",
    "import random\n",
    "import base64\n",
    "import pprint\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import gym\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from gym import wrappers\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from subprocess import check_output\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "LEAVE_PRINT_EVERY_N_SECS = 300\n",
    "ERASE_LINE = '\\x1b[2K'\n",
    "EPS = 1e-6\n",
    "BEEP = lambda: os.system(\"printf '\\a'\")\n",
    "RESULTS_DIR = os.path.join('..', 'results')\n",
    "SEEDS = (12, 34, 56, 78, 90)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3547ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "params = {\n",
    "    'figure.figsize': (15, 8),\n",
    "    'font.size': 24,\n",
    "    'legend.fontsize': 20,\n",
    "    'axes.titlesize': 28,\n",
    "    'axes.labelsize': 24,\n",
    "    'xtick.labelsize': 20,\n",
    "    'ytick.labelsize': 20\n",
    "}\n",
    "pylab.rcParams.update(params)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7214619f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f5dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_make_env_fn(**kargs):\n",
    "    def make_env_fn(env_name, seed=None, render=None, record=False,\n",
    "                    unwrapped=False, monitor_mode=None, \n",
    "                    inner_wrappers=None, outer_wrappers=None):\n",
    "        mdir = tempfile.mkdtemp()\n",
    "        env = None\n",
    "        if render:\n",
    "            try:\n",
    "                env = gym.make(env_name, render=render)\n",
    "            except:\n",
    "                pass\n",
    "        if env is None:\n",
    "            env = gym.make(env_name)\n",
    "        if seed is not None: env.seed(seed)\n",
    "        env = env.unwrapped if unwrapped else env\n",
    "        if inner_wrappers:\n",
    "            for wrapper in inner_wrappers:\n",
    "                env = wrapper(env)\n",
    "        env = wrappers.Monitor(\n",
    "            env, mdir, force=True, \n",
    "            mode=monitor_mode, \n",
    "            video_callable=lambda e_idx: record) if monitor_mode else env\n",
    "        if outer_wrappers:\n",
    "            for wrapper in outer_wrappers:\n",
    "                env = wrapper(env)\n",
    "        return env\n",
    "    return make_env_fn, kargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "340a6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_html(env_videos, title, max_n_videos=4):\n",
    "    videos = np.array(env_videos)\n",
    "    if len(videos) == 0:\n",
    "        return\n",
    "    \n",
    "    n_videos = max(1, min(max_n_videos, len(videos)))\n",
    "    idxs = np.linspace(0, len(videos) - 1, n_videos).astype(int) if n_videos > 1 else [-1,]\n",
    "    videos = videos[idxs,...]\n",
    "\n",
    "    strm = '<h2>{}<h2>'.format(title)\n",
    "    for video_path, meta_path in videos:\n",
    "        video = io.open(video_path, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "\n",
    "        with open(meta_path) as data_file:    \n",
    "            meta = json.load(data_file)\n",
    "\n",
    "        html_tag = \"\"\"\n",
    "        <h3>{0}<h3/>\n",
    "        <video width=\"960\" height=\"540\" controls>\n",
    "            <source src=\"data:video/mp4;base64,{1}\" type=\"video/mp4\" />\n",
    "        </video>\"\"\"\n",
    "        strm += html_tag.format('Episode ' + str(meta['episode_id']), encoded.decode('ascii'))\n",
    "    return strm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c602abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gif_html(env_videos, title, subtitle_eps=None, max_n_videos=4):\n",
    "    videos = np.array(env_videos)\n",
    "    if len(videos) == 0:\n",
    "        return\n",
    "    \n",
    "    n_videos = max(1, min(max_n_videos, len(videos)))\n",
    "    idxs = np.linspace(0, len(videos) - 1, n_videos).astype(int) if n_videos > 1 else [-1,]\n",
    "    videos = videos[idxs,...]\n",
    "\n",
    "    strm = '<h2>{}<h2>'.format(title)\n",
    "    for video_path, meta_path in videos:\n",
    "        basename = os.path.splitext(video_path)[0]\n",
    "        gif_path = basename + '.gif'\n",
    "        if not os.path.exists(gif_path):\n",
    "            ps = subprocess.Popen(\n",
    "                ('ffmpeg', \n",
    "                 '-i', video_path, \n",
    "                 '-r', '7',\n",
    "                 '-f', 'image2pipe', \n",
    "                 '-vcodec', 'ppm',\n",
    "                 '-crf', '20',\n",
    "                 '-vf', 'scale=512:-1',\n",
    "                 '-'), \n",
    "                stdout=subprocess.PIPE)\n",
    "            output = subprocess.check_output(\n",
    "                ('convert',\n",
    "                 '-coalesce',\n",
    "                 '-delay', '7',\n",
    "                 '-loop', '0',\n",
    "                 '-fuzz', '2%',\n",
    "                 '+dither',\n",
    "                 '-deconstruct',\n",
    "                 '-layers', 'Optimize',\n",
    "                 '-', gif_path), \n",
    "                stdin=ps.stdout)\n",
    "            ps.wait()\n",
    "\n",
    "        gif = io.open(gif_path, 'r+b').read()\n",
    "        encoded = base64.b64encode(gif)\n",
    "            \n",
    "        with open(meta_path) as data_file:    \n",
    "            meta = json.load(data_file)\n",
    "\n",
    "        html_tag = \"\"\"\n",
    "        <h3>{0}<h3/>\n",
    "        <img src=\"data:image/gif;base64,{1}\" />\"\"\"\n",
    "        prefix = 'Trial ' if subtitle_eps is None else 'Episode '\n",
    "        sufix = str(meta['episode_id'] if subtitle_eps is None \\\n",
    "                    else subtitle_eps[meta['episode_id']])\n",
    "        strm += html_tag.format(prefix + sufix, encoded.decode('ascii'))\n",
    "    return strm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b6f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenderUnit8(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    def reset(self, **kwargs):\n",
    "        return self.env.reset(**kwargs)\n",
    "    def render(self, mode ='rgb_array'):\n",
    "        frame = self.env.render(mode= mode)\n",
    "        return frame.astype(np.unit8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b11ddb",
   "metadata": {},
   "source": [
    "# DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a447c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCQV(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 output_dim, \n",
    "                 hidden_dims = (32, 32), \n",
    "                 activation_fc = F.relu):\n",
    "        super(FCQV, self).__init__()\n",
    "        self.activation_fc = activation_fc \n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dims[0])\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims) -1): \n",
    "            in_dim = hidden_dims[i]\n",
    "            if i == 0: \n",
    "                in_dim += output_dim \n",
    "            hidden_layer = nn.Linear(in_dim, hidden_dims[i+1])\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], 1)\n",
    "\n",
    "        device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda:0\"\n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def _format(self, state, action):\n",
    "        x, u = state, action \n",
    "\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, device = self.device, dtype = torch.float32)\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "        if not isinstance(u, torch.Tensor):\n",
    "            u = torch.tensor(u, device = self.device, dtype = torch.float32)\n",
    "            u = u.unsqueeze(0)\n",
    "        \n",
    "        return x, u \n",
    "    \n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x, u = self._format(state, action)\n",
    "        x = self.activation_fc(self.input_layer(x))\n",
    "        for i, hidden_layer in enumerate(self.hidden_layers):\n",
    "            if i == 0:\n",
    "                x = torch.cat((x,u), dim = 1)\n",
    "            x = self.activation_fc(hidden_layer(x))\n",
    "\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "    def load(self, experiences):\n",
    "        states, actions, new_states, rewards, is_terminals = experiences\n",
    "        states = torch.from_numpy(states).float().to(self.device)\n",
    "        actions = torch.from_numpy(actions).float().to(self.device)\n",
    "        new_states = torch.from_numpy(new_states).float().to(self.device)\n",
    "        rewards = torch.from_numpy(rewards).float().to(self.device)\n",
    "        is_terminals = torch.from_numpy(is_terminals).float().to(self.device)\n",
    "        return states, actions, new_states, rewards, is_terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCDP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim, \n",
    "                 action_bounds, \n",
    "                 hidden_dims  = (32, 32), \n",
    "                 activation_fc = F.relu, \n",
    "                 out_activation_fc = F.tanh\n",
    "                 ):\n",
    "        super(FCDP, self)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
